# This is a basic workflow takes care of building and deploying
# catalog when creating merge request to main branch

# Workflow for deploying content to bucket
name: Deploy test static content to s3 bucket

on:
  pull_request:
    types:
      - opened
      - synchronize
    branches:
      - 'main'

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.
# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.
concurrency:
  group: "bucket_deploy"
  cancel-in-progress: false

jobs:
  deploy:
    environment:
      name: test_deploy
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v3
      - name: Setup Pages
        uses: actions/configure-pages@v3
      - name: Install dependencies
        run: |
          pip install -U pip
          pip install -r generators/requirements.txt
      - name: Build
        env:
          SH_INSTANCE_ID: ${{ secrets.SH_INSTANCE_ID }}
          SH_CLIENT_ID: ${{ secrets.SH_CLIENT_ID }}
          SH_CLIENT_SECRET: ${{ secrets.SH_CLIENT_SECRET }}
        run: |
          cd generators/
          python generate_indicators.py
      # Upload build to S3 using cp
      - name: Upload folder to bucket
        uses: a-sync/s3-uploader@v2
        with:
          args: --recursive
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_REGION: 'eu-central-1'
          S3_BUCKET: ${{ secrets.AWS_S3_BUCKET }}
          S3_KEY: 'catalog/${GITHUB_REF##*/}'
          FILE: ./build

